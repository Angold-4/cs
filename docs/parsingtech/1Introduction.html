<!DOCTYPE html>
<html lang="en"
      xmlns:og="http://ogp.me/ns#"
      xmlns:fb="https://www.facebook.com/2008/fbml">
<head>
    <title>Angold-4 Organization</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <link href="../../../images/favicon.png" rel="icon">
<link rel="canonical" href=".">
        <meta name="author" content="Angold Wang" />

    <meta property="og:site_name" content="Angold-4" />
<!--     <meta property="og:type" content="article"/> -->
    <meta property="og:title" content="Angold-4 Organization"/>
    <meta property="og:url" content="."/>

    <!-- Bootstrap -->
        <link rel="stylesheet" href="../../../theme/css/bootstrap.flatly.min.css" type="text/css"/>
    <link href="../../../theme/css/font-awesome.min.css" rel="stylesheet">
<!--     <link href="https://cdnjs.cloudflare.com/ajax/libs/typicons/2.0.9/typicons.min.css" rel="stylesheet"> -->

    <link href="../../../theme/css/pygments/monokai.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../theme/css/style.css" type="text/css"/>

  <style>

    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }

    li {
      font-size: 18px;
    }

    p {
      font-size: 18px;
    }

    a {
      font-size: 18px;
    }

    k

    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }

    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }

    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
    {   }

    @media screen {
      pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }

    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>

</head>
<body>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
<!-- <script src="https://code.jquery.com/jquery-2.2.4.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script> -->

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="http://angold4.org" class="navbar-brand">
<img src="../../../images/logo.png" width="32"/> Angold4            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
			    <li><a href="../../../about.html">About</a>
                            <li><a href="../../../blogs.html">Blogs</a>
                            <li><a href="../../../projects.html">Projects</a>

	    </ul>
            <ul class="nav navbar-nav navbar-right">
                <li> <a title="Youtube" href="https://www.youtube.com/channel/UC3ZAjh2LHhm-FrgxgBtgMzQ" target="_new"><i class="fa fa-youtube"></i> Youtube</a>
		</li>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->


<div class="container">
    <div class="row">
        <div class="col-lg-12">
	<section id="content" class="body">
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#parsing-techniques-notes-by-angold-wang"
id="toc-parsing-techniques-notes-by-angold-wang">Parsing Techniques
Notes by Angold Wang</a></li>
<li><a href="#parsing-and-grammars" id="toc-parsing-and-grammars">1.
Parsing and Grammars</a>
<ul>
<li><a href="#in-computer-science" id="toc-in-computer-science">In
Computer Science</a></li>
<li><a href="#in-linguistics" id="toc-in-linguistics">In
Linguistics</a></li>
<li><a href="#an-overview-of-parsing" id="toc-an-overview-of-parsing">1.
An Overview of Parsing</a>
<ul>
<li><a href="#i.-the-target-of-parsing"
id="toc-i.-the-target-of-parsing">i. The Target of Parsing</a></li>
<li><a href="#ii.-the-purpose-of-parsing"
id="toc-ii.-the-purpose-of-parsing">ii. The Purpose of Parsing</a></li>
</ul></li>
<li><a href="#grammars-as-a-generating-device"
id="toc-grammars-as-a-generating-device">2. Grammars as a Generating
Device</a>
<ul>
<li><a href="#i.-describing-a-language-through-a-finite-recipe."
id="toc-i.-describing-a-language-through-a-finite-recipe.">i. Describing
a language through a finite recipe.</a></li>
<li><a href="#ii.-formal-grammars" id="toc-ii.-formal-grammars">ii.
Formal Grammars</a></li>
</ul></li>
<li><a href="#the-chomsky-hierarchy-of-grammars"
id="toc-the-chomsky-hierarchy-of-grammars">3. The Chomsky Hierarchy of
Grammars</a>
<ul>
<li><a href="#type-1-grammars" id="toc-type-1-grammars">Type 1
grammars</a></li>
<li><a href="#type-2-grammars" id="toc-type-2-grammars">Type 2
grammars</a></li>
<li><a href="#type-3-grammars" id="toc-type-3-grammars">Type 3
grammars</a></li>
<li><a href="#type-4-grammars" id="toc-type-4-grammars">Type 4
grammars</a></li>
<li><a href="#a-comparision-of-grammar-types"
id="toc-a-comparision-of-grammar-types">A comparision of grammar
types</a></li>
</ul></li>
</ul></li>
</ul>
</nav>
<h3 id="parsing-techniques-notes-by-angold-wang">Parsing Techniques
Notes by Angold Wang</h3>
<h1 id="parsing-and-grammars">1. Parsing and Grammars</h1>
<p>Include Chapter 1 &amp; 2 of the book: <strong><a
href="ParsingTechniques.pdf">Parsing Techniques</a></strong>.</p>
<p><strong>Parsing (syntactic analysis) is probably one of the best
understood branches of computer science.</strong> And of course parsers
are being used extensively in a number of disciplines:</p>
<h3 id="in-computer-science">In Computer Science</h3>
<ul>
<li><strong>Compiler Construction</strong></li>
<li><strong>Database Interfaces</strong></li>
<li><strong>Artificial Intelligence</strong></li>
<li>…</li>
</ul>
<h3 id="in-linguistics">In Linguistics</h3>
<ul>
<li><strong>Text and Textual Analysis</strong></li>
<li><strong>Natual language Translation and Recongnition</strong></li>
<li><strong>Corpora Analysis</strong></li>
<li>…</li>
</ul>
<p>In this series: <strong><a href="https://angold4.org/cs/">Parsing
Techniques Notes</a></strong>, I’m trying to illustrate the basic
concepts, and techniques of <strong>Parsing</strong>, which are the
notes of the book: <strong><a href="ParsingTechniques.pdf">Parsing
Techniques</a></strong> by <strong>Dick Grune</strong> and
<strong>Ceriel Jacobs</strong>.</p>
<h2 id="an-overview-of-parsing">1. An Overview of Parsing</h2>
<p><strong>“Parsing is the process of structuring a linear
representation in accordance with a given grammar”</strong>.</p>
<p>If you do not know what parsing is, here is the definition. But you
may still confuse with that after reading it. Since this definition has
been kept abstract on purpose, to allow as wide an interpretation as
possible.</p>
<h3 id="i.-the-target-of-parsing">i. The Target of Parsing</h3>
<p>The <strong>“linear representation”</strong> that shown in the
definition may be a sentence, a computer program, a knitting pattern, a
sequence of geological strata, or even a piece of music. and they do
have something in common:</p>
<ol type="1">
<li><p>Any linear representation (sequence) has some
<strong>rule</strong> with it, which tells the parser whether it is an
valid sequence, and tells us the meaning of the representation. We call
that rule <strong>grammar</strong>.</p></li>
<li><p>Any linear representation (sequence) in which the
<strong>preceding elements in some way restrict the next
element</strong>.</p>
<ul>
<li>For example: Consider a simple calculator
“<strong><code>1 + 2 =</code></strong>”: if the preciciding element in
that expression is a number, say <code>3</code>, <strong>it will
restrict its next element so that it can only be a symbol (e,g.
<code>+</code>)</strong>.</li>
<li>If there is no restriction, the sequence still has a grammar, but
this grammar is trivial, uninformative and hard to understand.</li>
</ul></li>
</ol>
<h3 id="ii.-the-purpose-of-parsing">ii. The Purpose of Parsing</h3>
<p>For each grammar, there are generally an infinite number of linear
representations (aka “sentence”) that can be structured with it.
<strong>The finite-size grammar can supply structure to an infinite
number of sentences.</strong> And that is the purpose of a grammar:
<strong>To Summarize succinctly the structure of an infinite number of
objects of a certain class.”</strong></p>
<p>In general, there are two reasons to perform this structuring process
called parsing:</p>
<ol type="1">
<li><p><strong>After parsing a given sentence, we can show that whether
this sentence can be recongnized according to a grammar.</strong> And
for the error-repairing parsers, they can suggest possible word classes
for missing or unknown words on clay tablets.</p></li>
<li><p><strong>Grammars usually have semantics attached to them</strong>
(Specific sementics is attached to specific rules); <strong>The obtained
structure (e.g. parse tree) of parsing can help us to process the
sentence fucther. (understand its semantics)</strong></p>
<ul>
<li>The obtained structure often shows which rules were involved in the
production of a string and how.</li>
<li>Reconginition is not enough, we need parsing to get the full benefit
of the syntactic approach.</li>
</ul></li>
</ol>
<h2 id="grammars-as-a-generating-device">2. Grammars as a Generating
Device</h2>
<p>Everyone who has studied a foreign language knows that a grammar is a
book of rules and examples which describes and teaches the language. The
computer scientist takes a very abstracted view of it, which not only
can grammar describe a language, <strong>but also it should show the
recipe of that language (the recipe should imply how a sentence can be
constructed).</strong></p>
<p>Quite unlike human, the computer needs a <strong>clear,
well-understood and unambiguous grammar</strong> in order to process its
language. In the human’s world, the linguist holds his view of language
because it gives him a formal tight grip on a seemingly chaotic and
perhaps infinitely complex object: <strong>natual language</strong>, and
understand its meaning through the human’s heart.</p>
<h3 id="i.-describing-a-language-through-a-finite-recipe.">i. Describing
a language through a finite recipe.</h3>
<p><strong>A good way to build a set of objects is to start with a small
object and to give rules how to add to it and construct new objects from
it.</strong> For example, “Two is an even number and the sum of two even
numbers is again an even number” effectively generates the set of all
even numbers.</p>
<p>Suppose we want to generate the set of all enumerations of names, of
the type “Tom, Dick and Harry”, in which all names but the last two are
separated by commas.</p>
<p>For example, in this case, we will not accept “Tom, Dick, Harry” nor
“Tom and Dick and Harry”. And Only “Tom, Dick and Harry” would be right.
<strong>A simple-minded recipe would be:</strong></p>
<h4 id="recipe-1">Recipe #1</h4>
<ol type="1">
<li>Tom is a name, Dick is a name, Harry is a name;</li>
<li>a name is a sentence;</li>
<li>a sentence followed by a comma and a name is again a sentence;</li>
<li>before finishing, if the sentence ends in “, name”, replace it by
“and name”.</li>
</ol>
<p><strong>Although this seems will work for a cooperative reader, there
are several things wrong with it:</strong></p>
<h4 id="problems-of-recipe-1">Problems of Recipe #1</h4>
<ol type="1">
<li><strong>In Clause 3, the sentence does not really end in “, name”,
it actually end in “, Dick” or such.</strong>
<ul>
<li>The “name” is just a symbol that stands for the real name. it will
be replaced by a real name as given in rule 1.</li>
<li><strong>To Solve it, we define that there are two kinds of symbols
involved here: terminals and non-terminals</strong>.</li>
<li><strong>terminals</strong> (short for “terminal symbols”) are
symbols that will occur in finished sentences. (e.g, “tom”)</li>
<li><strong>non-terminals</strong> (a singularly unin-spired term) which
are the intermediate symbols that cannot occured in a finished
sentence.</li>
</ul></li>
<li><strong>As I mentioned above, the computer needs a clear and
generative grammar in order to process its language.</strong>
<ul>
<li>In Clause 1, the “<span class="math inline">\(X\)</span> is a <span
class="math inline">\(Y\)</span>” should be replaced by “<span
class="math inline">\(Y\)</span> may be replaced by <span
class="math inline">\(X\)</span>”.</li>
</ul></li>
</ol>
<p><strong>This gives us the Recipe #2:</strong></p>
<p>(To distinguish them, we write terminals in small letters and start
non-terminals with a bond capital.)</p>
<h4 id="recipe-2">Recipe #2</h4>
<ol type="1">
<li><strong>Name</strong> may be replaced by “tom” |
<strong>Name</strong> may be replaced by “dick” | <strong>Name</strong>
may be replaced by “harry”</li>
<li><strong>Sentence</strong> may be replaced by
<strong>Name</strong></li>
<li><strong>Sentence</strong> may be replaced by <strong>Sentence,
Name</strong></li>
<li><strong>“, Name”</strong> at the end of a <strong>Sentence</strong>
must be replaced by <strong>“and Name”</strong> before
<strong>Name</strong> is replaced by any of its replacements</li>
<li>a sentence is finished only when it no longer contains
non-terminals</li>
<li>we start our replacement procedure with
<strong>Sentence</strong></li>
</ol>
<p>Clause 1 through 4 describe replacements, Clause 5 is not specific to
this grammar. It is valid generally and is one of the rules of the game.
Clause 7 tells us where to start generating.</p>
<h4 id="problem-of-recipe-2">Problem of Recipe #2</h4>
<p>The Only problem of recipe #2 is also in Clause 4: most rules have
“may be replaced”, but this one has “must be replaced”. And since we
want a more generic and elegant grammar, we only want to use <strong>may
be replaced</strong> in all of our rules.</p>
<p>This can be solved by adding an <strong>end-marker</strong> after it.
And if we make the <strong>end-marker</strong> a
<strong>non-terminal</strong> which cannot be used anywhere except in
the required replacement from “, Name” to “and Name”, we automatically
<strong>enforce the restriction that no sentence is finished unless the
replacement test has taken place.</strong></p>
<p>Then for brevity we write <span class="math inline">\(\to\)</span>
instead of “may be replaced by” and here comes the final recipe #3:</p>
<h4 id="recipe-3">Recipe #3</h4>
<ol type="1">
<li><strong>Name</strong> <span class="math inline">\(\to\)</span> tom |
<strong>Name</strong> <span class="math inline">\(\to\)</span> dick |
<strong>Name</strong> <span class="math inline">\(\to\)</span>
harry</li>
<li><strong>Sentence</strong> <span class="math inline">\(\to\)</span>
<strong>Name</strong> | <strong>Sentence</strong> <span
class="math inline">\(\to\)</span> <strong>List</strong> End</li>
<li><strong>List</strong> <span class="math inline">\(\to\)</span> Name
| <strong>List</strong> <span class="math inline">\(\to\)</span>
<strong>List, Name</strong></li>
<li><strong>, Name End</strong> <span class="math inline">\(\to\)</span>
and <strong>Name</strong></li>
<li>the start symbol is <strong>Sentence</strong></li>
</ol>
<p>As we can see, <strong>we have succeeded in implementing the notion
“must replace” in a system that only uses “may replace”; looking more
closely, we see that we have split “must replace” into “may replace” and
“must not be a non-terminal”.</strong></p>
<p>The above recipe form #3, based on replacement according to rules, is
strong enough to serve as a basis for <strong>formal
grammars.</strong></p>
<h3 id="ii.-formal-grammars">ii. Formal Grammars</h3>
<p>Here, based on Recipe #3, we will give a formal definition of
grammars, but before that, let me introduce the two reasons for having a
<strong>formal definition</strong>:</p>
<ol type="1">
<li><strong>It allows us to be very precise</strong>, then we’ll know
exactly what we means by a <strong>grammar</strong> and should answer
any question about what counts and what doesn’t count.</li>
<li>We can use this <strong>formal notation</strong> rather than as a
kind of a picture when we want to represents them in formal
articles.</li>
</ol>
<h4 id="the-definition-of-formal-grammars">The definition of formal
grammars</h4>
<p><strong>A</strong> <em>generative grammar</em> <strong>is a 4-tuple
<span class="math inline">\((V_N, V_T, R, S)\)</span> such
that:</strong></p>
<ol type="1">
<li><p><strong><span class="math inline">\(V_N\)</span> and <span
class="math inline">\(V_T\)</span> are finite sets of
symbols.</strong></p></li>
<li><p><strong><span class="math inline">\(V_N \cap V_T =
\varnothing\)</span></strong></p></li>
<li><p><strong><span class="math inline">\(R\)</span> is a set of pairs
<span class="math inline">\((P, Q)\)</span> such that:</strong></p>
<ul>
<li><p><span class="math inline">\(P \in (V_N \cup
V_T)^+\)</span></p></li>
<li><p><span class="math inline">\(Q \in (V_N \cup
V_T)^*\)</span></p></li>
</ul></li>
<li><p><strong><span class="math inline">\(S \in
V_N\)</span></strong></p></li>
</ol>
<p>A 4-tuple is just an object consisting of 4 identifiable parts; they
are the <strong>non-terminals</strong>, <strong>the terminals</strong>,
the <strong>rules</strong> and the <strong>start symbol</strong>, in
that order. For our grammars we have:</p>
<p><span class="math display">\[
V_N = {\mathbf Name, \mathbf Sentence, \mathbf List, \mathbf End}
\]</span></p>
<p><span class="math display">\[
V_T = {tom, dick, harry, \mathbf, , and}
\]</span></p>
<p>The intersection of <span class="math inline">\(V_N\)</span> and
<span class="math inline">\(V_T\)</span> (2) must be empty, that is, the
non-terminals and the terminals may not have a symbol in common, which
is understandable.</p>
<p><span class="math inline">\(R\)</span> is the set of all rules (3),
and <span class="math inline">\(P\)</span> and <span
class="math inline">\(Q\)</span> are the left-hand sides and right-hand
sides, respectively. Each <span class="math inline">\(P\)</span> must
consist of sequences of <strong>one or more non-terminals and
terminals</strong> and each <span class="math inline">\(Q\)</span> must
consist of sequences of <strong>zero or more non-terminals and
terminals</strong>.</p>
<p>The start symbol <span class="math inline">\(S\)</span> must be an
element of <span class="math inline">\(V_N\)</span>, that is, it must be
a non-terminal:</p>
<p><span class="math display">\[
S = \mathbf Sentence
\]</span></p>
<h4 id="generating-sentences-from-a-formal-grammar">Generating sentences
from a formal grammar</h4>
<p>Now, let’s using our formal grammar to generate some sentences. For
your convinence, I’ll put the <a
href="https://angold4.org/cs/docs/parsingtech/1Introduction.html#Recipe-#3">Recipe
#3</a> here, with some little changes: 1. Several right-hand sides for
one and the same left-hand side are <strong>grouped together</strong>
and separated by vertical bars. 2. The non-terminal with the subscript
<span class="math inline">\(_s\)</span> is the start symbol.</p>
<figure>
<img src="Sources/grammar.png" alt="grammar" />
<figcaption aria-hidden="true">grammar</figcaption>
</figure>
<p>Now let’s generate our initial example from this grammar, using
replacement according to the above rules only. We obtain the following
successive forms for <strong>Sentence</strong>:</p>
<figure>
<img src="Sources/replacement.png" alt="replacement" />
<figcaption aria-hidden="true">replacement</figcaption>
</figure>
<p>The intermediate forms are called <em>sentential forms</em>;
<strong>if a sentential form contains no non-terminals it is called a
sentence and belongs to the generated language</strong>. The transitions
from one line to the next are called production steps and the rules are
often called production rules.</p>
<p>This production process can be made more visual by drawing connective
lines between corresponding symbols, such a picture is called
<em>production graph</em> or <em>syntactic graph</em>, because
<strong>it depicts the syntactic structure (with regard to the given
grammar) of the finial sentence</strong></p>
<figure>
<img src="Sources/production.svg" alt="production" />
<figcaption aria-hidden="true">production</figcaption>
</figure>
<h2 id="the-chomsky-hierarchy-of-grammars">3. The Chomsky Hierarchy of
Grammars</h2>
<p>The example above shows us indeed <strong>some simple phrase
structure grammars can actually generate very complicated sets</strong>.
Moreover, by giving the definition of <strong>formal grammars</strong>
(e.g. instantiate the grammar), we can now try to deal with our problem
– <strong>How to parsing</strong>.</p>
<p>The <strong>Formal Grammars</strong> was first studied extensively by
<strong><a href="https://en.wikipedia.org/wiki/Noam_Chomsky">Noam
Chomsky</a></strong> in 1959. His analysis has been the foundation for
almost all research and progress in formal languages, parsers and a
considerable part of compiler construction and linguistics.</p>
<blockquote>
<p>According to Chomsky’s hypothesis, the reason why humans can speak is
that humans are born with a dedicated circuit for acquiring production
rules in the brain. Because humans have the ability to acquire
<strong>recursive language rules</strong>, they become able to speak
languages. Non-human animals do not have the ability to acquire
language, which he attributed to the absence of circuits in the
non-human brains for acquiring production rules. Chomsky’s claims, which
have not been substantiated or disproved nearly 60 years after the
hypothesis was published, are still considered quite convincing.</p>
</blockquote>
<p>In practice, the grammar can be so complex, <strong>we shall see that
now general parsing algorithm for them can exist, and all known special
parsing algorithms are either very inefficient or very complex.</strong>
The desire to <strong>restrict the unmanageability of phrase structure
grammars,</strong> while keeping as much of their generative powers as
possible, has led the <em>Chomsky hierarchy of grammars</em>.</p>
<p>This hierarchy distinguishes four types of grammars numbered from 0
to 3. Type 0 grammars are the (unrestricted phrase structure grammars of
which we have already seen examples). The other types originate from
<strong>applying more and more restrictions</strong> to the allowed form
of the rules in the grammar, by applying these restrictions:</p>
<ul>
<li>The resulting grammars are gradually easier to understand and to
manipulate.</li>
<li>But their <strong>generative power</strong> are gradually less
powerful.</li>
</ul>
<p>Fortunately, these less powerful types are still very useful,
actually more useful even than Type 0. We shall now introduce each of
the three remaining types in turn:</p>
<h3 id="type-1-grammars">Type 1 grammars</h3>
<h4 id="definition">Definition:</h4>
<ul>
<li><strong>Definition 1: A grammar is</strong> <em>Type 1
monotonic</em> <strong>if it contains no rules in which the left hand
side consists of more symbols than the right hand side.</strong>
<ul>
<li>Example: <strong><span class="math inline">\(,\)</span> <span
class="math inline">\(Name\)</span> <span
class="math inline">\(End\)</span> <span
class="math inline">\(\to\)</span> <span
class="math inline">\(and\)</span> <span
class="math inline">\(Name\)</span></strong> is prohibited in type
1.</li>
</ul></li>
</ul>
<figure>
<img src="Sources/type1monotonic.png" alt="type1monotonic" />
<figcaption aria-hidden="true">type1monotonic</figcaption>
</figure>
<ul>
<li><strong>Definition 2: A grammar is</strong> <em>Type 1
context-sensitive</em> <strong>if all of its rules are
context-sensitive.</strong>
<ul>
<li>Context-sensitive: <strong>Only one (non-terminal) symbol in its
left-hand side gets replaced by other symbols</strong>.</li>
</ul></li>
</ul>
<figure>
<img src="Sources/type1contexts.png" alt="type1contexts" />
<figcaption aria-hidden="true">type1contexts</figcaption>
</figure>
<p>We can prove that: <strong>Monotonic and context-sensitive grammars
are equally powerful.</strong> They all classified as Type 1 grammars,
and both of them are less powerful than the Type 0 grammars, that is,
there are languages that can be generated by a Type 0 grammar but now by
any Type 1.</p>
<h4 id="example">Example:</h4>
<p>The standard example of a Type 1 language is the set of words that
consist of equal numbers of a’s, b’s and c’s: <span
class="math display">\[
a^n  b^n  c^n
\]</span></p>
<p>Since usually it is not that easy to give a grammar of Type 1
language by human. For the sake of completeness, I just put the correct
grammar here, with a derivation tree for <span
class="math inline">\(a^2b^2c^2\)</span> as an example to show the
derivation process.</p>
<figure>
<img src="Sources/type1ans.png" alt="type1ans" />
<figcaption aria-hidden="true">type1ans</figcaption>
</figure>
<figure>
<img src="Sources/type1derivation.png" alt="type1derivation" />
<figcaption aria-hidden="true">type1derivation</figcaption>
</figure>
<p>You may find that although Type 1 grammars (also called as
context-sensitive grammars) can express correlations, but the grammar is
not in a way that human can understand.</p>
<h3 id="type-2-grammars">Type 2 grammars</h3>
<h4 id="definition-1">Definition:</h4>
<ul>
<li><strong>Definition: A grammar is</strong> <em>Type 2 context-free
grammars</em> <strong>if all of its rules are context-free.</strong>
<ul>
<li>Context-free: <strong>Only single non-ternminal are allowed on the
left-hand side.</strong></li>
</ul></li>
</ul>
<figure>
<img src="Sources/type2contextf.png" alt="type2contextf" />
<figcaption aria-hidden="true">type2contextf</figcaption>
</figure>
<figure>
<img src="Sources/cfex.svg" alt="cfex.svg" />
<figcaption aria-hidden="true">cfex.svg</figcaption>
</figure>
<p>Comparing to the Type 1 (CS) grammar, the Type2 (CF) grammer have the
following properties:</p>
<ol type="1">
<li><p>Since there is always only one symbol on the left-hand side, each
node in a production graph has the property that whatever it produces is
independent of what is neighbours produce: <strong>The productive life
of a non-terminal is independent of its context.</strong> (That is why
it is called context-free). Unlike context-sensitive grammars, which has
to look at its neighbours on the left and on the right to see what
production rules are allowed for it.</p></li>
<li><p>The production graph will consequently has a pure tree-form
called a <em>production tree</em>.</p></li>
<li><p>Since there is only one symbol on the left-hand side, all
right-hand sides for a given non-terminal; can always be collected in
one grammar rule, and then each grammar reads like a
<strong>definition</strong> of the left-hand side.</p></li>
</ol>
<h4 id="examples">Examples:</h4>
<p>The standard example of a Type 2 language is also equal numbers of
words, but only for 2 different words.</p>
<p><span class="math display">\[
a^n  b^n
\]</span></p>
<p>And the CF grammar is pretty easy, which is human-understandable.</p>
<p><span class="math display">\[
S \to a S b  \vert  ab
\]</span></p>
<h4 id="the-limitations-of-cf-grammars">The limitations of CF
grammars:</h4>
<p>When one has been working for a while with CF grammars, one gradually
gets the feeling that almost anything could be expressed in a CF
grammar. However, serious limitations to what can be said by a CF
grammar is shown by the famous <em>uvwxy</em> theorem (also called
<strong>pumping lemma</strong>). And by using this lemma, we can easily
prove that whether a language can be expressed using a CF grammar.</p>
<h4 id="pumping-lemma-for-cfls">Pumping Lemma for CFLs:</h4>
<p><strong>For every CFL <span class="math inline">\(A\)</span>, there
is a <span class="math inline">\(p\)</span> such that if <span
class="math inline">\(s\)</span> <span
class="math inline">\(\in\)</span> <span
class="math inline">\(A\)</span> and <span
class="math inline">\(|s|\)</span> <span
class="math inline">\(\ge\)</span> <span
class="math inline">\(p\)</span> then <span
class="math inline">\(s\)</span> <span class="math inline">\(=\)</span>
<span class="math inline">\(uvxyz\)</span> where:</strong></p>
<ol type="1">
<li><p><span class="math inline">\(uv^ixy^iz \in A\)</span> for all
<span class="math inline">\(i \ge 0\)</span>.</p></li>
<li><p>$vy $</p></li>
<li><p><span class="math inline">\(|vxy| \le p\)</span></p></li>
</ol>
<p><strong>Any sentence generated by a CF grammar, that is longer than
the longest original sentence from that grammar, can be cut into five
pieces <span class="math inline">\(u,v,w,x\)</span> and <span
class="math inline">\(y\)</span> in such a way that <span
class="math inline">\(uv^nwx^ny\)</span> is a sentence from that grammar
for all <span class="math inline">\(n \ge 0\)</span></strong></p>
<figure>
<img src="Sources/pumping.png" alt="pumping" />
<figcaption aria-hidden="true">pumping</figcaption>
</figure>
<p>All long unoriginal string s that CF generates have this
<strong>pumping quality</strong>:</p>
<p><strong>You can break them up into five pieces, so that the second
and forth piece can be repeated and stay in the language.</strong></p>
<figure>
<img src="Sources/pump.png" alt="pump" />
<figcaption aria-hidden="true">pump</figcaption>
</figure>
<h3 id="type-3-grammars">Type 3 grammars</h3>
<h4 id="definition-2">Definition:</h4>
<ul>
<li><strong>Definition: A grammar is</strong> <em>Type 3 regular
grammars</em> <strong>if all of its rules are regular.</strong>
<ul>
<li>Regular #1: <strong>A non-terminal produces zero or more
terminals.</strong></li>
<li>Regular #2: <strong>A non-terminal produces zero or more terminals
followed by one non-terminal.</strong></li>
</ul></li>
</ul>
<p>Type 3 grammars are also called <em>regular grammars</em> or
<em>finite-state</em> grammars. Since regular grammars are used very
often to describe the structure of text on the character level.
(e.g. <strong>classification of different tokens</strong>)</p>
<h3 id="type-4-grammars">Type 4 grammars</h3>
<p>The last restriction we shall apply to what is allowed in a
production rule is a pretty final one: <strong>no non-terminal is
allowed in the right-hand side.</strong> This removes all the generative
power from the mechanism, except for the choosing of alternatives, which
will only introduce a finite number of terminals.</p>
<p>The type 4 grammar is also called finite-choice grammar. And it can
only be used in some limited situations (e.g. <strong>classification of
different chars</strong>).</p>
<h3 id="a-comparision-of-grammar-types">A comparision of grammar
types</h3>
<figure>
<img src="Sources/summary.png" alt="summary" />
<figcaption aria-hidden="true">summary</figcaption>
</figure>
<figure>
<img src="Sources/30grammar.png" alt="30grammar" />
<figcaption aria-hidden="true">30grammar</figcaption>
</figure>
<p>This differece between these grammars has been depicted
metaphorically in the rose figure above, in which a rose is approximated
by increasingly finer outlines. In this metaphor, the <strong>rose
corresponds to the language</strong> (imagine the sentences of the
language as molecules in the rose); <strong>the grammar serves to
delineate its silhouette.</strong> * A <strong>regular grammar</strong>
only allows us straight horizontal and vertical line segments to
describe the flower; ruler and T-square suffice, but the result is a
coarse and mechanical-looking picture. * A <strong>CF grammar</strong>
would approximate the outline by straight lines at any angle and by
circle segments; the drawing could still be made using the classical
tools of compasses and ruler. The result is stilted but recognizable. *
A <strong>CS grammar</strong> would present us with a smooth curve
tightly enveloping the flower, but the curve is too smooth: it cannot
follow all the sharp turns and it deviates slightly at complicated
points; still, a very realistic picture results. * An
<strong>unrestricted phrase structure grammar</strong> can represent the
outline perfectly. The rose itself cannot be caught in a finite
description; its essence remains forever out of our reach.</p>
<p>A more prosaic and practical example can be found in the successive
sets of <strong>Pascal</strong> programs that can be generated by the
various grammar types.</p>
<ul>
<li><p><strong>The set of all lexically correct Pascal programs can be
generated by a regular grammar.</strong></p>
<ul>
<li>A Pascal program is lexically correct if there are no newlines
insidstrings, comment is terminated before end-of-file, all numerical
constants have the right form, etc.</li>
</ul></li>
<li><p><strong>The set of all syntactically correct Pascal programs can
be generated by a context-free grammar.</strong></p></li>
<li><p><strong>The set of all semantically correct Pascal programs can
be generated by a CS grammar</strong></p>
<ul>
<li>A Pascal programs is semantically correct if it will pass through a
Pascal compiler without drawing error messages.</li>
</ul></li>
<li><p><strong>The set of all Pascal programs that would terminate in
finite time when run with a given input can be generated by an
unrestricted phrase structure grammar.</strong></p></li>
<li><p><strong>The set of all Pascal programs that solve a given
problem</strong> (for instance, play chess) cannot be generated by a
grammar (although the description of the set is finite).</p></li>
</ul>
	</section>
	</div>
    </div>

<div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
this.page.url = "https://angold4.org/cs/docs/parsingtech/1Introduction.html"
this.page.identifier = "cs/docs/parsingtech/1Introduction.html"

    };
    (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://angold.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

</div>
<footer>
   <div class="well well-lg" id="footer-well">
      <div class="container">


      <div class="row">
         <div class="col-xs-6">
            <a href="https://angold4.org" title="Angold-4 Organization" class="image-link"><img src="../../../images/logo.png" class="cmudb-logo" /></a>
         </div>
         <div class="col-xs-6">
            <p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p>
        </div>
      </div>
   </div>
   </div>
</footer>
<!-- Include all compiled plugins (below), or include individual files as needed -->

<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<script src="../../../theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="../../../theme/js/respond.min.js"></script>

<!-- Fix scrolling issues to internal HREFs that get positioned behind navbar -->
<!-- http://stackoverflow.com/questions/10732690/offsetting-an-html-anchor-to-adjust-for-fixed-header -->
<script src="../../../theme/js/href_scroll.js"></script>

<!-- You know what this is and you know what he did to me... -->
<script src="../../../theme/js/tim-kraska-betrayed-me.js"></script>
</body>
</html>

